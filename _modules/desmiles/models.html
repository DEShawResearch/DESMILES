<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>desmiles.models &mdash; desmiles  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> desmiles
          </a>
              <div class="version">
                BETA
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../desmiles.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../release-notes.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../issues.html">Open issues</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">desmiles</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">Module code</a> &raquo;</li>
      <li>desmiles.models</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for desmiles.models</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">fastai.torch_core</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">fastai.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">fastai.text.models.awd_lstm</span> <span class="kn">import</span> <span class="n">EmbeddingDropout</span><span class="p">,</span> <span class="n">RNNDropout</span><span class="p">,</span> <span class="n">WeightDropout</span><span class="p">,</span> <span class="n">dropout_mask</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils.rnn</span> <span class="kn">import</span> <span class="n">pad_packed_sequence</span><span class="p">,</span> <span class="n">pack_padded_sequence</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DesmilesCore&#39;</span><span class="p">,</span> <span class="s1">&#39;LinearDecoder&#39;</span><span class="p">,</span> <span class="s1">&#39;Desmiles&#39;</span><span class="p">,</span> <span class="s1">&#39;RecurrentDESMILES&#39;</span><span class="p">,</span> <span class="s1">&#39;FPEmbedder&#39;</span><span class="p">,</span> <span class="s1">&#39;EmbeddingToSMILES&#39;</span><span class="p">,</span>
           <span class="s1">&#39;FingerprintEmbedderCore&#39;</span><span class="p">,</span> <span class="s1">&#39;get_desmiles_model&#39;</span><span class="p">,</span> <span class="s1">&#39;get_fp_to_embedding_model&#39;</span><span class="p">,</span> <span class="s1">&#39;get_embedded_fp_to_smiles_model&#39;</span><span class="p">]</span>


<div class="viewcode-block" id="DesmilesCore"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.DesmilesCore">[docs]</a><span class="k">class</span> <span class="nc">DesmilesCore</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Core Piece of DESMILES</span>
<span class="sd">       Does everything except final softmax layer (LinearDecoder)</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">initrange</span><span class="o">=</span><span class="mf">0.1</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">fp_emb_sz</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">emb_sz</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">n_hid</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">pad_token</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bidir</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">hidden_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">input_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">embed_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">weight_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">qrnn</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="mi">4096</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bs</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">qrnn</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">ndir</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">qrnn</span><span class="p">,(</span><span class="mi">2</span> <span class="k">if</span> <span class="n">bidir</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb_sz</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hid</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">emb_sz</span><span class="p">,</span><span class="n">n_hid</span><span class="p">,</span><span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_sz</span><span class="p">,</span> <span class="n">emb_sz</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="n">pad_token</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_dp</span> <span class="o">=</span> <span class="n">EmbeddingDropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="n">embed_p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">emb_sz</span> <span class="k">if</span> <span class="n">l</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">n_hid</span><span class="p">,</span> <span class="p">(</span><span class="n">n_hid</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">emb_sz</span><span class="p">)</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">ndir</span><span class="p">,</span>
                             <span class="mi">1</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidir</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span> <span class="o">=</span> <span class="p">[</span><span class="n">WeightDropout</span><span class="p">(</span><span class="n">rnn</span><span class="p">,</span> <span class="n">weight_p</span><span class="p">)</span> <span class="k">for</span> <span class="n">rnn</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnns</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">initrange</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">initrange</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_dp</span> <span class="o">=</span> <span class="n">RNNDropout</span><span class="p">(</span><span class="n">input_p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dps</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">RNNDropout</span><span class="p">(</span><span class="n">hidden_p</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_fp</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">bn_drop_lin</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="n">fp_emb_sz</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">actn</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">bn_drop_lin</span><span class="p">(</span><span class="n">fp_emb_sz</span><span class="p">,</span> <span class="n">n_hid</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">actn</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_fp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_fp</span><span class="p">)</span>
            

<div class="viewcode-block" id="DesmilesCore.forward"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.DesmilesCore.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_seq</span><span class="p">,</span> <span class="n">input_fp</span><span class="p">,</span> <span class="n">lengths</span><span class="p">):</span>

        <span class="n">sl</span><span class="p">,</span><span class="n">bs</span> <span class="o">=</span> <span class="n">input_seq</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">bs</span><span class="o">!=</span><span class="bp">self</span><span class="o">.</span><span class="n">bs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bs</span><span class="o">=</span><span class="n">bs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="c1"># Apply LinearBlocks on input_fp</span>
        <span class="n">emb_fp</span> <span class="o">=</span> <span class="n">input_fp</span>
        <span class="k">for</span> <span class="n">linear_fp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_fp</span><span class="p">:</span>
            <span class="n">emb_fp</span> <span class="o">=</span> <span class="n">linear_fp</span><span class="p">(</span><span class="n">emb_fp</span><span class="p">)</span>
        <span class="n">raw_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder_dp</span><span class="p">(</span><span class="n">input_seq</span><span class="p">))</span>
        <span class="n">raw_outputs</span><span class="p">,</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">[],[]</span>
        <span class="k">for</span> <span class="n">l</span><span class="p">,</span> <span class="p">(</span><span class="n">rnn</span><span class="p">,</span><span class="n">hid_dp</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnns</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dps</span><span class="p">)):</span>
            <span class="n">raw_output</span> <span class="o">=</span> <span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">raw_output</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">l</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">raw_output</span><span class="p">,</span> <span class="n">new_h</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="n">raw_output</span><span class="p">,</span> <span class="p">(</span><span class="n">emb_fp</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">emb_fp</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">raw_output</span><span class="p">,</span> <span class="n">new_h</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="n">raw_output</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>
            <span class="n">raw_output</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">raw_output</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">raw_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">raw_output</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span> <span class="n">raw_output</span> <span class="o">=</span> <span class="n">hid_dp</span><span class="p">(</span><span class="n">raw_output</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">l</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span> <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">raw_output</span><span class="p">)</span>
        <span class="c1">#self.hidden = to_detach(new_hidden, cpu=False)</span>
        <span class="k">return</span> <span class="n">raw_outputs</span><span class="p">,</span> <span class="n">outputs</span></div>

    <span class="k">def</span> <span class="nf">_one_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">l</span><span class="p">:</span><span class="nb">int</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="s2">&quot;Return one hidden state.&quot;</span>
        <span class="n">nh</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hid</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_sz</span><span class="p">)</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">ndir</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bs</span><span class="p">,</span> <span class="n">nh</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

<div class="viewcode-block" id="DesmilesCore.reset"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.DesmilesCore.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;Reset the hidden states.&quot;</span>
        <span class="p">[</span><span class="n">r</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="s1">&#39;reset&#39;</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">_one_hidden</span><span class="p">(</span><span class="n">l</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_one_hidden</span><span class="p">(</span><span class="n">l</span><span class="p">))</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">)]</span></div></div>

<div class="viewcode-block" id="LinearDecoder"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.LinearDecoder">[docs]</a><span class="k">class</span> <span class="nc">LinearDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s2">&quot;To go on top of a DesmilesCore module and create a DESMILES Model.&quot;</span>
    <span class="n">initrange</span><span class="o">=</span><span class="mf">0.1</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_out</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">n_hid</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">output_p</span><span class="p">:</span><span class="nb">float</span><span class="p">,</span> <span class="n">tie_encoder</span><span class="p">:</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hid</span><span class="p">,</span> <span class="n">n_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">initrange</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">initrange</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dp</span> <span class="o">=</span> <span class="n">RNNDropout</span><span class="p">(</span><span class="n">output_p</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">bias</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">tie_encoder</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">tie_encoder</span><span class="o">.</span><span class="n">weight</span>

<div class="viewcode-block" id="LinearDecoder.forward"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.LinearDecoder.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span><span class="n">Tensor</span><span class="p">])</span><span class="o">-&gt;</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span><span class="n">Tensor</span><span class="p">,</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">raw_outputs</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="nb">input</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dp</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">decoded</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">decoded</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">result</span><span class="p">,</span> <span class="n">raw_outputs</span><span class="p">,</span> <span class="n">outputs</span></div></div>


<div class="viewcode-block" id="Desmiles"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.Desmiles">[docs]</a><span class="k">class</span> <span class="nc">Desmiles</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s2">&quot;Combines DesmilesCore with LinearDecoder for a full model&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">desmiles_rnn_core</span><span class="p">,</span> <span class="n">linear_decoder</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">desmiles_rnn_core</span> <span class="o">=</span> <span class="n">desmiles_rnn_core</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_decoder</span> <span class="o">=</span> <span class="n">linear_decoder</span>

<div class="viewcode-block" id="Desmiles.reset"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.Desmiles.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">desmiles_rnn_core</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_decoder</span><span class="p">]:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="s1">&#39;reset&#39;</span><span class="p">):</span>
                <span class="n">c</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span></div>

<div class="viewcode-block" id="Desmiles.forward"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.Desmiles.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_seq</span><span class="p">,</span> <span class="n">input_fp</span><span class="p">,</span> <span class="n">lengths</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">desmiles_rnn_core</span><span class="p">(</span><span class="n">input_seq</span><span class="p">,</span> <span class="n">input_fp</span><span class="p">,</span> <span class="n">lengths</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_decoder</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span></div>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">key</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">desmiles_rnn_core</span>
        <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_decoder</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Indexing only supports 0 or 1&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="get_desmiles_model"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.get_desmiles_model">[docs]</a><span class="k">def</span> <span class="nf">get_desmiles_model</span><span class="p">(</span><span class="n">vocab_sz</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">fp_emb_sz</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">emb_sz</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">n_hid</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">pad_token</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">tie_weights</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">qrnn</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bidir</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">output_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">hidden_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">input_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
                       <span class="n">embed_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">weight_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="mi">4096</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="s2">&quot;Create a full DESMILES model.&quot;</span>
    <span class="n">rnn_enc</span> <span class="o">=</span> <span class="n">DesmilesCore</span><span class="p">(</span><span class="n">vocab_sz</span><span class="p">,</span> <span class="n">fp_emb_sz</span><span class="p">,</span> <span class="n">emb_sz</span><span class="p">,</span> <span class="n">n_hid</span><span class="o">=</span><span class="n">n_hid</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">pad_token</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span> <span class="n">qrnn</span><span class="o">=</span><span class="n">qrnn</span><span class="p">,</span> <span class="n">bidir</span><span class="o">=</span><span class="n">bidir</span><span class="p">,</span>
                              <span class="n">hidden_p</span><span class="o">=</span><span class="n">hidden_p</span><span class="p">,</span> <span class="n">input_p</span><span class="o">=</span><span class="n">input_p</span><span class="p">,</span> <span class="n">embed_p</span><span class="o">=</span><span class="n">embed_p</span><span class="p">,</span> <span class="n">weight_p</span><span class="o">=</span><span class="n">weight_p</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="mi">4096</span><span class="p">)</span>
    <span class="n">enc</span> <span class="o">=</span> <span class="n">rnn_enc</span><span class="o">.</span><span class="n">encoder</span> <span class="k">if</span> <span class="n">tie_weights</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Desmiles</span><span class="p">(</span><span class="n">rnn_enc</span><span class="p">,</span> <span class="n">LinearDecoder</span><span class="p">(</span><span class="n">vocab_sz</span><span class="p">,</span> <span class="n">emb_sz</span><span class="p">,</span> <span class="n">output_p</span><span class="p">,</span> <span class="n">tie_encoder</span><span class="o">=</span><span class="n">enc</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">model</span></div>


<div class="viewcode-block" id="RecurrentDESMILES"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.RecurrentDESMILES">[docs]</a><span class="k">class</span> <span class="nc">RecurrentDESMILES</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    RecurrentDESMILES is a reimplimentation of DESMILES model which provides separate functions</span>
<span class="sd">    for the fingerprint embedding and the decoding. This is used heavily in decoding methods </span>
<span class="sd">    such as beam search and A*</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">initrange</span><span class="o">=</span><span class="mf">0.1</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">desmiles</span><span class="p">,</span> <span class="n">fp_embedding_layers</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">desmiles</span> <span class="o">=</span> <span class="n">desmiles</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fp_embedding_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">linear_fp</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">fp_embedding_layers</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">rnn</span> <span class="k">for</span> <span class="n">rnn</span> <span class="ow">in</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">rnns</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_layer</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb_sz</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">emb_sz</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nhid</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">n_hid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nlayers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnns</span><span class="p">)</span>

<div class="viewcode-block" id="RecurrentDESMILES.embed_fingerprints"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.RecurrentDESMILES.embed_fingerprints">[docs]</a>    <span class="k">def</span> <span class="nf">embed_fingerprints</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fps</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">desmiles</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">fps</span><span class="o">.</span><span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bs</span> <span class="o">=</span> <span class="n">fps</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span> <span class="c1"># reset the hidden state every time we get a new fingerprint</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">embedded</span> <span class="o">=</span> <span class="n">fps</span>
            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fp_embedding_layers</span><span class="p">:</span>
                <span class="n">embedded</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hiddens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">embedded</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">embedded</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span></div>

<div class="viewcode-block" id="RecurrentDESMILES.forward"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.RecurrentDESMILES.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq</span><span class="p">):</span>
        <span class="n">sl</span><span class="p">,</span><span class="n">bs</span> <span class="o">=</span> <span class="n">seq</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">bs</span><span class="o">!=</span><span class="bp">self</span><span class="o">.</span><span class="n">bs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bs</span><span class="o">=</span><span class="n">bs</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="p">(</span><span class="n">seq</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">lengths</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">rnn</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnns</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hiddens</span><span class="p">)):</span>                
                <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">hiddens</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">hidden</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_layer</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="RecurrentDESMILES.one_hidden"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.RecurrentDESMILES.one_hidden">[docs]</a>    <span class="k">def</span> <span class="nf">one_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">l</span><span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
        <span class="n">nh</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nhid</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nlayers</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_sz</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bs</span><span class="p">,</span> <span class="n">nh</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> </div>

<div class="viewcode-block" id="RecurrentDESMILES.reset"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.RecurrentDESMILES.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hiddens</span> <span class="o">=</span> <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">one_hidden</span><span class="p">(</span><span class="n">l</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">one_hidden</span><span class="p">(</span><span class="n">l</span><span class="p">))</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nlayers</span><span class="p">)]</span></div>

<div class="viewcode-block" id="RecurrentDESMILES.set_hiddens"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.RecurrentDESMILES.set_hiddens">[docs]</a>    <span class="k">def</span> <span class="nf">set_hiddens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hiddens</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">hiddens</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hiddens</span> <span class="o">=</span> <span class="n">hiddens</span></div>

<div class="viewcode-block" id="RecurrentDESMILES.select_hidden"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.RecurrentDESMILES.select_hidden">[docs]</a>    <span class="k">def</span> <span class="nf">select_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hiddens</span> <span class="o">=</span> <span class="p">[(</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="n">idxs</span><span class="p">,:],</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">][:,</span><span class="n">idxs</span><span class="p">,:])</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hiddens</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">idxs</span><span class="p">)</span></div></div>

<span class="c1">#################################################################################</span>
<span class="c1">########################### Code to Split Model #################################</span>
<span class="c1">#################################################################################</span>


<div class="viewcode-block" id="FPEmbedder"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.FPEmbedder">[docs]</a><span class="k">class</span> <span class="nc">FPEmbedder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Maps fingerprints to their pretrained embedding space</span>
<span class="sd">        For simplicity of loading weights from DESMILES, I create a copy of DESMILESRNNCore</span>
<span class="sd">        and just replace the forward() method</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">initrange</span><span class="o">=</span><span class="mf">0.1</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">fp_emb_sz</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">emb_sz</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">n_hid</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">pad_token</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bidir</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">hidden_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">input_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">embed_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">weight_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">qrnn</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">first_layer</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">first_layer</span> <span class="o">=</span> <span class="n">first_layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bs</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">qrnn</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">ndir</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">qrnn</span><span class="p">,(</span><span class="mi">2</span> <span class="k">if</span> <span class="n">bidir</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb_sz</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hid</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">emb_sz</span><span class="p">,</span><span class="n">n_hid</span><span class="p">,</span><span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_sz</span><span class="p">,</span> <span class="n">emb_sz</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="n">pad_token</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_dp</span> <span class="o">=</span> <span class="n">EmbeddingDropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="n">embed_p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">emb_sz</span> <span class="k">if</span> <span class="n">l</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">n_hid</span><span class="p">,</span> <span class="p">(</span><span class="n">n_hid</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">emb_sz</span><span class="p">)</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">ndir</span><span class="p">,</span>
                             <span class="mi">1</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidir</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span> <span class="o">=</span> <span class="p">[</span><span class="n">WeightDropout</span><span class="p">(</span><span class="n">rnn</span><span class="p">,</span> <span class="n">weight_p</span><span class="p">)</span> <span class="k">for</span> <span class="n">rnn</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnns</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">initrange</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">initrange</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_dp</span> <span class="o">=</span> <span class="n">RNNDropout</span><span class="p">(</span><span class="n">input_p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dps</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">RNNDropout</span><span class="p">(</span><span class="n">hidden_p</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_fp</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">bn_drop_lin</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="n">fp_emb_sz</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">actn</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">bn_drop_lin</span><span class="p">(</span><span class="n">fp_emb_sz</span><span class="p">,</span> <span class="n">n_hid</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">actn</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_fp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_fp</span><span class="p">)</span>


<div class="viewcode-block" id="FPEmbedder.forward"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.FPEmbedder.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_fp</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">first_layer</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_fp</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">input_fp</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_fp</span><span class="p">:</span>
            <span class="n">input_fp</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">input_fp</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">input_fp</span></div></div>

<div class="viewcode-block" id="EmbeddingToSMILES"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.EmbeddingToSMILES">[docs]</a><span class="k">class</span> <span class="nc">EmbeddingToSMILES</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Maps embedding space of fingerprints to SMILES</span>
<span class="sd">       For simplicity of loading weights from DESMILES, I create a copy of DESMILSE and just replace</span>
<span class="sd">       the forward() method</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">desmiles_rnn_core</span><span class="p">,</span> <span class="n">linear_decoder</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">desmiles_rnn_core</span> <span class="o">=</span> <span class="n">desmiles_rnn_core</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_decoder</span> <span class="o">=</span> <span class="n">linear_decoder</span>

<div class="viewcode-block" id="EmbeddingToSMILES.reset"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.EmbeddingToSMILES.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">desmiles_rnn_core</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_decoder</span><span class="p">]:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="s1">&#39;reset&#39;</span><span class="p">):</span>
                <span class="n">c</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span></div>

<div class="viewcode-block" id="EmbeddingToSMILES.forward"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.EmbeddingToSMILES.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_seq</span><span class="p">,</span> <span class="n">input_fp</span><span class="p">,</span> <span class="n">lengths</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">desmiles_rnn_core</span><span class="p">(</span><span class="n">input_seq</span><span class="p">,</span> <span class="n">input_fp</span><span class="p">,</span> <span class="n">lengths</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_decoder</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span></div>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">key</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">desmiles_rnn_core</span>
        <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_decoder</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Indexing only supports 0 or 1&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="FingerprintEmbedderCore"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.FingerprintEmbedderCore">[docs]</a><span class="k">class</span> <span class="nc">FingerprintEmbedderCore</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Maps embedding space of fingerprints to SMILES</span>
<span class="sd">       For simplicity of loading weights from DESMILES, I create a copy of DESMILSE and just replace</span>
<span class="sd">       the forward() method</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">initrange</span><span class="o">=</span><span class="mf">0.1</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">fp_emb_sz</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">emb_sz</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">n_hid</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">pad_token</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bidir</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">hidden_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">input_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">embed_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">weight_p</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">qrnn</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">first_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">first_layer</span> <span class="o">=</span> <span class="n">first_layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bs</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">qrnn</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">ndir</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">qrnn</span><span class="p">,(</span><span class="mi">2</span> <span class="k">if</span> <span class="n">bidir</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb_sz</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hid</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">emb_sz</span><span class="p">,</span><span class="n">n_hid</span><span class="p">,</span><span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_sz</span><span class="p">,</span> <span class="n">emb_sz</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="n">pad_token</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_dp</span> <span class="o">=</span> <span class="n">EmbeddingDropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="n">embed_p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">emb_sz</span> <span class="k">if</span> <span class="n">l</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">n_hid</span><span class="p">,</span> <span class="p">(</span><span class="n">n_hid</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">emb_sz</span><span class="p">)</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">ndir</span><span class="p">,</span>
                             <span class="mi">1</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidir</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span> <span class="o">=</span> <span class="p">[</span><span class="n">WeightDropout</span><span class="p">(</span><span class="n">rnn</span><span class="p">,</span> <span class="n">weight_p</span><span class="p">)</span> <span class="k">for</span> <span class="n">rnn</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnns</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">initrange</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">initrange</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_dp</span> <span class="o">=</span> <span class="n">RNNDropout</span><span class="p">(</span><span class="n">input_p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dps</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">RNNDropout</span><span class="p">(</span><span class="n">hidden_p</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_fp</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">bn_drop_lin</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="n">fp_emb_sz</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">actn</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">bn_drop_lin</span><span class="p">(</span><span class="n">fp_emb_sz</span><span class="p">,</span> <span class="n">n_hid</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">actn</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_fp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_fp</span><span class="p">)</span>
            

<div class="viewcode-block" id="FingerprintEmbedderCore.forward"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.FingerprintEmbedderCore.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_seq</span><span class="p">,</span> <span class="n">input_fp</span><span class="p">,</span> <span class="n">lengths</span><span class="p">):</span>

        <span class="n">sl</span><span class="p">,</span><span class="n">bs</span> <span class="o">=</span> <span class="n">input_seq</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">bs</span><span class="o">!=</span><span class="bp">self</span><span class="o">.</span><span class="n">bs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bs</span><span class="o">=</span><span class="n">bs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="c1"># Apply LinearBlocks on input_fp</span>
        <span class="n">emb_fp</span> <span class="o">=</span> <span class="n">input_fp</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">first_layer</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">linear_fp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_fp</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
                <span class="n">emb_fp</span> <span class="o">=</span> <span class="n">linear_fp</span><span class="p">(</span><span class="n">emb_fp</span><span class="p">)</span>
        <span class="n">raw_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder_dp</span><span class="p">(</span><span class="n">input_seq</span><span class="p">))</span>
        <span class="n">raw_outputs</span><span class="p">,</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">[],[]</span>
        <span class="k">for</span> <span class="n">l</span><span class="p">,</span> <span class="p">(</span><span class="n">rnn</span><span class="p">,</span><span class="n">hid_dp</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnns</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dps</span><span class="p">)):</span>
            <span class="n">raw_output</span> <span class="o">=</span> <span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">raw_output</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">l</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">raw_output</span><span class="p">,</span> <span class="n">new_h</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="n">raw_output</span><span class="p">,</span> <span class="p">(</span><span class="n">emb_fp</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">emb_fp</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">raw_output</span><span class="p">,</span> <span class="n">new_h</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="n">raw_output</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>
            <span class="n">raw_output</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">raw_output</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">raw_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">raw_output</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span> <span class="n">raw_output</span> <span class="o">=</span> <span class="n">hid_dp</span><span class="p">(</span><span class="n">raw_output</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">l</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span> <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">raw_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">raw_outputs</span><span class="p">,</span> <span class="n">outputs</span></div>

    <span class="k">def</span> <span class="nf">_one_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">l</span><span class="p">:</span><span class="nb">int</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="s2">&quot;Return one hidden state.&quot;</span>
        <span class="n">nh</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hid</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_sz</span><span class="p">)</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">ndir</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bs</span><span class="p">,</span> <span class="n">nh</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

<div class="viewcode-block" id="FingerprintEmbedderCore.reset"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.FingerprintEmbedderCore.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;Reset the hidden states.&quot;</span>
        <span class="p">[</span><span class="n">r</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="s1">&#39;reset&#39;</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">_one_hidden</span><span class="p">(</span><span class="n">l</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_one_hidden</span><span class="p">(</span><span class="n">l</span><span class="p">))</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">)]</span></div></div>

<div class="viewcode-block" id="get_fp_to_embedding_model"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.get_fp_to_embedding_model">[docs]</a><span class="k">def</span> <span class="nf">get_fp_to_embedding_model</span><span class="p">(</span><span class="n">desmiles</span><span class="p">,</span> <span class="n">first_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
    <span class="n">fp_emb_sz</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">linear_fp</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">out_features</span>
    <span class="n">emb_sz</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">emb_sz</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">linear_fp</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">in_features</span>
    <span class="n">n_tok</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">nhid</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">rnns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">hidden_size</span>
    <span class="n">nlayers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">rnns</span><span class="p">)</span>
    <span class="n">pad_token</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">padding_idx</span>
    <span class="n">fp_to_embedding</span> <span class="o">=</span> <span class="n">FPEmbedder</span><span class="p">(</span><span class="n">n_tok</span><span class="p">,</span> <span class="n">fp_emb_sz</span><span class="p">,</span> <span class="n">emb_sz</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">pad_token</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span> <span class="n">first_layer</span><span class="o">=</span><span class="n">first_layer</span><span class="p">)</span>
    <span class="n">fp_to_embedding_dict</span> <span class="o">=</span> <span class="n">fp_to_embedding</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
    <span class="n">pretrained_dict</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
    <span class="n">pretrained_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pretrained_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">fp_to_embedding_dict</span><span class="p">}</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">pretrained_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">fp_to_embedding_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">fp_to_embedding_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">pretrained_dict</span><span class="p">)</span>
    <span class="n">fp_to_embedding</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">fp_to_embedding_dict</span><span class="p">)</span>
    <span class="n">fp_to_embedding</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">fp_to_embedding</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>

<div class="viewcode-block" id="get_embedded_fp_to_smiles_model"><a class="viewcode-back" href="../../desmiles.html#desmiles.models.get_embedded_fp_to_smiles_model">[docs]</a><span class="k">def</span> <span class="nf">get_embedded_fp_to_smiles_model</span><span class="p">(</span><span class="n">desmiles</span><span class="p">,</span> <span class="n">first_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
    <span class="n">fp_emb_sz</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">linear_fp</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">out_features</span>
    <span class="n">emb_sz</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">emb_sz</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">linear_fp</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">in_features</span>
    <span class="n">n_tok</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">nhid</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">rnns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">hidden_size</span>
    <span class="n">nlayers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">rnns</span><span class="p">)</span>
    <span class="n">pad_token</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">padding_idx</span>
    <span class="n">embedded_fp_to_encoded_core</span> <span class="o">=</span> <span class="n">FingerprintEmbedderCore</span><span class="p">(</span><span class="n">n_tok</span><span class="p">,</span> <span class="n">fp_emb_sz</span><span class="p">,</span> <span class="n">emb_sz</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">pad_token</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span> <span class="n">first_layer</span><span class="o">=</span><span class="n">first_layer</span><span class="p">)</span>
    <span class="n">trained_dict</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
    <span class="n">embedded_fp_to_encoded_core_dict</span> <span class="o">=</span> <span class="n">embedded_fp_to_encoded_core</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
    <span class="n">pretrained_dict</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
    <span class="n">pretrained_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pretrained_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">embedded_fp_to_encoded_core_dict</span><span class="p">}</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">pretrained_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">embedded_fp_to_encoded_core_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">embedded_fp_to_encoded_core_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">pretrained_dict</span><span class="p">)</span>
    <span class="n">embedded_fp_to_encoded_core</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">embedded_fp_to_encoded_core_dict</span><span class="p">)</span>
    <span class="n">linear_decoder</span> <span class="o">=</span> <span class="n">desmiles</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">embedded_fp_to_encoded</span> <span class="o">=</span> <span class="n">EmbeddingToSMILES</span><span class="p">(</span><span class="n">embedded_fp_to_encoded_core</span><span class="p">,</span> <span class="n">linear_decoder</span><span class="p">)</span>
    <span class="n">embedded_fp_to_encoded</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">embedded_fp_to_encoded</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, 2019, 2020, D. E. Shaw Research.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>